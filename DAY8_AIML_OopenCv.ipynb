{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d10ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "vid = cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\Pictures\\\\samplevideo.mp4\")\n",
    "inp = input(\"Enter the Time where you want to start: \")\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "count = 0\n",
    "\n",
    "while vid.isOpened():\n",
    "    _, frame = vid.read()\n",
    "    count += 1\n",
    "    if count >= int(fps * float(inp)):\n",
    "        frame = cv2.resize(frame, (640, 640), interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imshow(f\"Frames From {inp} Seconds-{count}\", frame)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid=cv2.VideoCapture(\"C:\\\\Users\\\\hp\\\\newRunning.mp4\")\n",
    "inp=input(\"Enter the Time where you want to start\")\n",
    "fps=vid.get(cv2.CAP_PROP_FPS)\n",
    "count=0\n",
    "while (vid.isOpened()):\n",
    "    _,frame=vid.read()\n",
    "    count+=1\n",
    "    if count >= int(fps*inp):\n",
    "        frame=cv2.resize(frame,(640,640),interpolation=cv2.INTER_CUBIC)\n",
    "        cv2.imshow(\"Frames From {inp} Seconds-{count}\",frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d28dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 384ms/step\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 0s 485ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "img = cv2.imread(\"C:\\\\Users\\hp\\\\Pictures\\\\istock.jpg\")\n",
    "faces = detector.detect_faces(img)\n",
    "for face in faces:\n",
    "    x, y, width, height = face['box']\n",
    "    cv2.rectangle(img, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "cv2.imshow('Face Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c34d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "img = cv2.imread('blur.jpg')\n",
    "faces = detector.detect_faces(img)\n",
    "#print(faces)\n",
    "color=(255, 0, 0)\n",
    "for face in faces:\n",
    "    if face['confidence'] > 0.98 :\n",
    "        x, y, width, height = face['box']\n",
    "        cv2.rectangle(img, (x, y), (x + width, y + height), color, 4)\n",
    "        points = face['keypoints']\n",
    "        eyeLeft = (points['left_eye'][0]- 10, points['left_eye'][1]-10 , 20, 20)\n",
    "        eyeRight = (points['right_eye'][0]-10, points['right_eye'][1]-10, 20, 20)\n",
    "        nose = (points['nose'][0]-15, points['nose'][1]-15, 30, 30)\n",
    "        mouth_left = (points['mouth_left'][0] - 15, points['mouth_left'][1] - 10, 30, 20)\n",
    "        mouth_right = (points['mouth_right'][0] - 15, points['mouth_right'][1] - 10, 30, 20)\n",
    "\n",
    "        cv2.rectangle(img, eyeLeft, color, 2)\n",
    "        cv2.rectangle(img, eyeRight, color, 2)\n",
    "        cv2.rectangle(img, nose, (0, 0, 255), 2)\n",
    "        cv2.rectangle(img, mouth_left, (0, 255, 0), 2)\n",
    "        cv2.rectangle(img, mouth_right, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a338682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 218ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "img = cv2.imread(\"C:\\\\Users\\\\hp\\\\Pictures\\\\animal.jpg\")\n",
    "faces = detector.detect_faces(img)\n",
    "for face in faces:\n",
    "    x, y, width, height = face['box']\n",
    "    cv2.rectangle(img, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "cv2.imshow('Face Detection', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ab414d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E969A42C00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 295ms/step\n",
      "Without Cam Faces: 0.9986139535903931\n",
      "Without Cam Faces: 0.9985405206680298\n",
      "Without Cam Faces: 0.9982202649116516\n",
      "Without Cam Faces: 0.9937440752983093\n",
      "Without Cam Faces: 0.9810194373130798\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "mtcnn = MTCNN()\n",
    "image = cv2.imread(\"C:\\\\Users\\hp\\\\Pictures\\\\istock.jpg\")\n",
    "faces = mtcnn.detect_faces(image)\n",
    "for face in faces:\n",
    "    if face['confidence'] > 0.999:\n",
    "        x, y, width, height = face['box']\n",
    "        keypoints = face['keypoints']\n",
    "        cv2.rectangle(image, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "        left_eye = (int(keypoints['left_eye'][0]), int(keypoints['left_eye'][1]))\n",
    "        right_eye = (int(keypoints['right_eye'][0]), int(keypoints['right_eye'][1]))\n",
    "        cv2.rectangle(img, eyeLeft, color, 2)\n",
    "        cv2.rectangle(img, eyeRight, color, 2)\n",
    "        \n",
    "        cv2.imshow(f\"With Cam Faces:{face['confidence']}\", image)\n",
    "        \n",
    "    else:\n",
    "        print(\"Without Cam Faces:\", face['confidence'])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c33dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"C:\\\\Users\\hp\\\\Pictures\\\\istock.jpg\")\n",
    "kernel=np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "outp=cv2.filter2D(img,-1,kernel)\n",
    "finall=cv2.add(img,outp)\n",
    "cv2.imshow(\"Original\",img)\n",
    "cv2.imshow(\"Modified\",outp)\n",
    "cv2.imshow(\"Modified2\",finall)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cc03c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
